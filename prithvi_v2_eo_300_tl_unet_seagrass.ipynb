{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Includes work derived from International Business Machines\n",
    "# `prithvi_v2_eo_300_tl_unet_multitemporal_crop.ipynb``\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# You may obtain a copy of the License at\n",
    "#  http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# All rights reserved for this derived work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/tylar/repos/nasa-prithvi-wetlands\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.3.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from nasa-prithvi-wetlands==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: pygbif>=0.6.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from nasa-prithvi-wetlands==0.1.0) (0.6.6)\n",
      "Requirement already satisfied: pyobis>=1.4.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from nasa-prithvi-wetlands==0.1.0) (1.4.1)\n",
      "Collecting terratorch (from nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading terratorch-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: rasterio in /home/tylar/miniconda3/lib/python3.12/site-packages (from nasa-prithvi-wetlands==0.1.0) (1.4.3)\n",
      "Requirement already satisfied: numpy in /home/tylar/miniconda3/lib/python3.12/site-packages (from nasa-prithvi-wetlands==0.1.0) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tylar/miniconda3/lib/python3.12/site-packages (from pandas>=1.3.0->nasa-prithvi-wetlands==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from pandas>=1.3.0->nasa-prithvi-wetlands==0.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tylar/miniconda3/lib/python3.12/site-packages (from pandas>=1.3.0->nasa-prithvi-wetlands==0.1.0) (2025.2)\n",
      "Requirement already satisfied: requests>2.7 in /home/tylar/miniconda3/lib/python3.12/site-packages (from pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: requests-cache in /home/tylar/miniconda3/lib/python3.12/site-packages (from pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (1.2.1)\n",
      "Requirement already satisfied: geojson_rewind in /home/tylar/miniconda3/lib/python3.12/site-packages (from pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (1.2.1)\n",
      "Requirement already satisfied: geomet in /home/tylar/miniconda3/lib/python3.12/site-packages (from pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/tylar/miniconda3/lib/python3.12/site-packages (from pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in /home/tylar/miniconda3/lib/python3.12/site-packages (from pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (3.10.3)\n",
      "Requirement already satisfied: affine in /home/tylar/miniconda3/lib/python3.12/site-packages (from rasterio->nasa-prithvi-wetlands==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: attrs in /home/tylar/miniconda3/lib/python3.12/site-packages (from rasterio->nasa-prithvi-wetlands==0.1.0) (25.4.0)\n",
      "Requirement already satisfied: certifi in /home/tylar/miniconda3/lib/python3.12/site-packages (from rasterio->nasa-prithvi-wetlands==0.1.0) (2025.4.26)\n",
      "Requirement already satisfied: click>=4.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from rasterio->nasa-prithvi-wetlands==0.1.0) (8.2.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /home/tylar/miniconda3/lib/python3.12/site-packages (from rasterio->nasa-prithvi-wetlands==0.1.0) (0.7.2)\n",
      "Requirement already satisfied: click-plugins in /home/tylar/miniconda3/lib/python3.12/site-packages (from rasterio->nasa-prithvi-wetlands==0.1.0) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in /home/tylar/miniconda3/lib/python3.12/site-packages (from rasterio->nasa-prithvi-wetlands==0.1.0) (3.2.3)\n",
      "Collecting torch>2.0 (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting rioxarray (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading rioxarray-0.20.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting albumentations==1.4.10 (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading albumentations-1.4.10-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting albucore==0.0.16 (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached albucore-0.0.16-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting torchmetrics (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: geopandas in /home/tylar/miniconda3/lib/python3.12/site-packages (from terratorch->nasa-prithvi-wetlands==0.1.0) (1.1.0)\n",
      "Collecting lightly (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading lightly-1.5.22-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting jsonargparse<=4.35.0 (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached jsonargparse-4.35.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting h5py (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting lightning (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading lightning-2.6.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting segmentation-models-pytorch==0.5.0 (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting torchgeo<0.7.2,>=0.7.0 (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading torchgeo-0.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting einops (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting timm>=1.0.15 (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached timm-1.0.22-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting pycocotools (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading pycocotools-2.0.10-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting huggingface_hub (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tifffile (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading tifffile-2025.10.16-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting python-box (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading python_box-7.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: tqdm in /home/tylar/miniconda3/lib/python3.12/site-packages (from terratorch->nasa-prithvi-wetlands==0.1.0) (4.66.5)\n",
      "Collecting wandb (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading wandb-0.23.1-py3-none-manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Collecting tensorboard (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /home/tylar/miniconda3/lib/python3.12/site-packages (from albucore==0.0.16->terratorch->nasa-prithvi-wetlands==0.1.0) (4.12.0.88)\n",
      "Collecting numpy (from nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (1.15.3)\n",
      "Collecting scikit-image>=0.21.0 (from albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML in /home/tylar/miniconda3/lib/python3.12/site-packages (from albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (4.15.0)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in /home/tylar/miniconda3/lib/python3.12/site-packages (from albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (2.12.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/tylar/miniconda3/lib/python3.12/site-packages (from segmentation-models-pytorch==0.5.0->terratorch->nasa-prithvi-wetlands==0.1.0) (11.2.1)\n",
      "Collecting safetensors>=0.3.1 (from segmentation-models-pytorch==0.5.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting filelock (from huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0) (2025.5.1)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/tylar/miniconda3/lib/python3.12/site-packages (from huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0) (24.1)\n",
      "Collecting shellingham (from huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/tylar/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->nasa-prithvi-wetlands==0.1.0) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tylar/miniconda3/lib/python3.12/site-packages (from requests>2.7->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tylar/miniconda3/lib/python3.12/site-packages (from requests>2.7->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from requests>2.7->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: setuptools in /home/tylar/miniconda3/lib/python3.12/site-packages (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0) (75.1.0)\n",
      "Collecting sympy>=1.13.3 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0) (3.5)\n",
      "Collecting jinja2 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting fiona>=1.8.22 (from torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading fiona-1.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
      "Collecting kornia>=0.7.4 (from torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached kornia-0.8.2-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pyproj>=3.4 in /home/tylar/miniconda3/lib/python3.12/site-packages (from torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0) (3.7.1)\n",
      "Collecting rtree>=1.0.1 (from torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: shapely>=1.8.5 in /home/tylar/miniconda3/lib/python3.12/site-packages (from torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0) (2.1.1)\n",
      "Collecting hydra-core>=1.0.0 (from lightly->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lightly_utils~=0.0.0 (from lightly->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pytorch_lightning>=1.0.4 (from lightly->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting aenum>=3.1.11 (from lightly->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from matplotlib->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tylar/miniconda3/lib/python3.12/site-packages (from matplotlib->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from matplotlib->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from matplotlib->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (1.4.8)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /home/tylar/miniconda3/lib/python3.12/site-packages (from geopandas->terratorch->nasa-prithvi-wetlands==0.1.0) (0.11.0)\n",
      "Requirement already satisfied: cattrs>=22.2 in /home/tylar/miniconda3/lib/python3.12/site-packages (from requests-cache->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (25.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/tylar/miniconda3/lib/python3.12/site-packages (from requests-cache->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (3.10.0)\n",
      "Requirement already satisfied: url-normalize>=1.4 in /home/tylar/miniconda3/lib/python3.12/site-packages (from requests-cache->pygbif>=0.6.0->nasa-prithvi-wetlands==0.1.0) (2.2.1)\n",
      "Requirement already satisfied: xarray>=2024.7.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from rioxarray->terratorch->nasa-prithvi-wetlands==0.1.0) (2025.4.0)\n",
      "INFO: pip is looking at multiple versions of rioxarray to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting rioxarray (from terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached rioxarray-0.19.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading sentry_sdk-2.47.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2027.0,>=2022.5.0->lightning->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio in /home/tylar/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/tylar/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/tylar/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0) (0.16.0)\n",
      "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kornia_rs>=0.1.9 (from kornia>=0.7.4->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting bitsandbytes<1.0,>=0.45.2 (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "INFO: pip is looking at multiple versions of lightning[pytorch-extra] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2 (from torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\n",
      "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading lightning-2.5.4-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading lightning-2.5.3-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\n",
      "  Using cached lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting rich<14.0,>=12.3.0 (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tensorboardX<3.0,>=2.2 (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albucore==0.0.16->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from pydantic>=2.7.0->albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/tylar/miniconda3/lib/python3.12/site-packages (from pydantic>=2.7.0->albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/tylar/miniconda3/lib/python3.12/site-packages (from pydantic>=2.7.0->albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (0.4.2)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image>=0.21.0->albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image>=0.21.0->albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->terratorch->nasa-prithvi-wetlands==0.1.0) (3.6.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>2.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting markupsafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting docstring-parser>=0.15 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached typeshed_client-2.8.2-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/tylar/miniconda3/lib/python3.12/site-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0) (2.19.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/tylar/miniconda3/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->terratorch->nasa-prithvi-wetlands==0.1.0) (1.3.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting importlib_resources>=1.4.0 (from typeshed-client>=2.1.0->jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo<0.7.2,>=0.7.0->terratorch->nasa-prithvi-wetlands==0.1.0)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading terratorch-1.1.1-py3-none-any.whl (560 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m560.3/560.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached albucore-0.0.16-py3-none-any.whl (9.5 kB)\n",
      "Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n",
      "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
      "Using cached jsonargparse-4.35.0-py3-none-any.whl (211 kB)\n",
      "Using cached timm-1.0.22-py3-none-any.whl (2.5 MB)\n",
      "Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchgeo-0.7.1-py3-none-any.whl (605 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.3/605.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading lightly-1.5.22-py3-none-any.whl (859 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.3/859.3 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycocotools-2.0.10-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (397 kB)\n",
      "Downloading python_box-7.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rioxarray-0.19.0-py3-none-any.whl (62 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2025.10.16-py3-none-any.whl (231 kB)\n",
      "Downloading wandb-0.23.1-py3-none-manylinux_2_28_x86_64.whl (22.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached aenum-3.1.16-py3-none-any.whl (165 kB)\n",
      "Downloading fiona-1.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Using cached kornia-0.8.2-py2.py3-none-any.whl (1.1 MB)\n",
      "Using cached lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
      "Using cached lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Using cached lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
      "Using cached markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n",
      "Using cached rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (507 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.47.0-py2.py3-none-any.whl (411 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached imageio-2.37.2-py3-none-any.whl (317 kB)\n",
      "Downloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached typeshed_client-2.8.2-py3-none-any.whl (760 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: nasa-prithvi-wetlands, antlr4-python3-runtime\n",
      "  Building editable for nasa-prithvi-wetlands (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nasa-prithvi-wetlands: filename=nasa_prithvi_wetlands-0.1.0-0.editable-py3-none-any.whl size=3781 sha256=20fd431c2c0ad3531a335eff5d99e3c4bb428dac7c7fd2df224e67437eeac78f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0z3dj1qp/wheels/50/94/6e/773c432450ded39d976f3502a7ad97d735512fa6460103d389\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=51dffaa08ed43ac2737fa4f0a73f4a1fa9f10a9868acd5cbb56a7e7a844f7870\n",
      "  Stored in directory: /home/tylar/.cache/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
      "Successfully built nasa-prithvi-wetlands antlr4-python3-runtime\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, antlr4-python3-runtime, aenum, typer-slim, triton, tensorboard-data-server, sympy, smmap, shellingham, sentry-sdk, safetensors, rtree, python-box, protobuf, propcache, omegaconf, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, multidict, mdurl, markupsafe, markdown, lightning-utilities, lazy-loader, kornia_rs, jsonargparse, importlib_resources, hf-xet, grpcio, frozenlist, filelock, einops, docstring-parser, aiohappyeyeballs, absl-py, yarl, werkzeug, typeshed-client, tifffile, tensorboardX, pycocotools, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, markdown-it-py, lightly_utils, jinja2, imageio, hydra-core, h5py, gitdb, fiona, aiosignal, tensorboard, scikit-image, rich, nvidia-cusolver-cu12, huggingface_hub, gitpython, albucore, aiohttp, wandb, torch, rioxarray, albumentations, torchvision, torchmetrics, kornia, bitsandbytes, timm, pytorch_lightning, segmentation-models-pytorch, lightning, lightly, torchgeo, terratorch, nasa-prithvi-wetlands\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bacc318390456b",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook focuses on fine-tuning the [Prithvi EO v2.0 model](https://huggingface.co/collections/ibm-nasa-geospatial/prithvi-for-earth-observation-6740a7a81883466bf41d93d6) to classify seagrass.\n",
    "\n",
    "This notebook:\n",
    "1. Is intended to be run on Google Colab.\n",
    "2. Uses Terratorch to fine-tune Prithvi EO v2.0 300m.\n",
    "3. Uses a seagrass patch dataset for fine-tuning derived from the IMaRS SIMM Seagrass Project.\n",
    "4. Uses fine-tuned model for inference.\n",
    "\n",
    "You may want to take this opportunity to double check you're using GPUs on Google Colab before proceeding any further. We have tested this notebook using T4 GPU on the free colab account.\n",
    "\n",
    "## Setup\n",
    "1. Install terratorch\n",
    "\n",
    "To install the necessary packages, execute the cell below. This will take a few minutes. Once the installation process is done, a window will pop up to ask you to restart the session. This is normal and you should proceed to restart using the interface in the pop up window. Once the session has restarted, its important that you ignore the cell below, and go straight to section 0.1.3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c25f3b",
   "metadata": {},
   "source": [
    "2. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c1961-311b-49e0-b6ea-2867b44cb47a",
   "metadata": {
    "id": "2e8c1961-311b-49e0-b6ea-2867b44cb47a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01malbumentations\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgdown\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gdown'"
     ]
    }
   ],
   "source": [
    "\n",
    "import albumentations\n",
    "import gdown\n",
    "import lightning.pytorch as pl\n",
    "import os\n",
    "import terratorch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from terratorch.datamodules import MultiTemporalCropClassificationDataModule\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b65b8e7cd7d65",
   "metadata": {},
   "source": [
    "A tuning dataset should be in the dataset_path directory.\n",
    "The dataset used is derived from the IMaRS SIMM Seagrasss Project.\n",
    "For methods to generate the patches, see the `py/generate_seagrass_patches.py` script in the repo.\n",
    "The patches then need to be split into training and validation sets.\n",
    "The sets are specified using a `.txt` file listing the patch file names for each set.\n",
    "Example `training_chips.txt`:\n",
    "\n",
    "```\n",
    "chip_257_266\n",
    "chip_328_501\n",
    "chip_171_477\n",
    "chip_236_281\n",
    "chip_134_482\n",
    "chip_120_493\n",
    "chip_161_390\n",
    "```\n",
    "\n",
    "The training and validation patches are expected to be in `training_chips` and `validation_chips` subdirectories of the dataset path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3t-YKKUztjXn",
   "metadata": {
    "id": "3t-YKKUztjXn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_path = \"data/tuning_patches\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20332275",
   "metadata": {},
   "source": [
    "4. Truncate the dataset for demonstration purposes. Reducing the training dataset to a third of the original size means that model training takes only a few minutes with the resources available during the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4517aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_truncation = 800\n",
    "validation_data_trunction = 4\n",
    "with open(f\"{dataset_path}/training_data.txt\", \"r\") as f:\n",
    "      training_data_list = f.readlines()\n",
    "truncated = training_data_list[0:training_data_truncation]\n",
    "with open(f\"{dataset_path}/training_data.txt\", \"w\") as f:\n",
    "    for i in truncated:\n",
    "        f.write(i)\n",
    "\n",
    "with open(f\"{dataset_path}/validation_data.txt\", \"r\") as f:\n",
    "      training_data_list = f.readlines()\n",
    "truncated = training_data_list[0:validation_data_trunction]\n",
    "with open(f\"{dataset_path}/validation_data.txt\", \"w\") as f:\n",
    "    for i in truncated:\n",
    "        f.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba4d58-8ff6-4f9c-bfb1-a70376f80494",
   "metadata": {
    "id": "35ba4d58-8ff6-4f9c-bfb1-a70376f80494"
   },
   "source": [
    "## Dataset Details\n",
    "\n",
    "Lets start with analysing the dataset. \n",
    "\n",
    "Please note: we have also set the batch_size parameter to 4 and max_epochs to 1 to avoid running out of memory or runtime for users of the free tier colab compute resources. This is enough to demonstrate the entire workflow to the user, but may not result in the best performance. It'll be best to find additional compute resources and increase batch_size and max_epochs in the downloaded config file for improved performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7d83440895e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each merged sample includes the stacked bands of three time steps\n",
    "!ls \"{dataset_path}/training_chips\" | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd1487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify parameters to select the batch size, number of workers, model backbone and epochs ahead of initalizing the MultiTemporalCropClassificationDataModule class for multi-temporal crop classification. \n",
    "batch_size = 4\n",
    "num_workers = 2\n",
    "prithvi_backbone = \"prithvi_eo_v2_300_tl\" # Model can be either prithvi_eo_v1_100, prithvi_eo_v2_300, prithvi_eo_v2_300_tl, prithvi_eo_v2_600, prithvi_eo_v2_600_tl\n",
    "\n",
    "# Total number of epochs the training will run for.\n",
    "max_epochs =  1 # Use 1 epoch for demos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91025bb8",
   "metadata": {},
   "source": [
    "#### Initialise the Datamodules class \n",
    "\n",
    "A Datamodule is a shareable, reusable class that encapsulates all the steps needed to process the data. Here we are using an adjusted dataset class for this dataset (general dataset class could be used as well). To learn more about MultiTemporalCropClassificationDataModule, take a look at the [TerraTorch docs](https://ibm.github.io/terratorch/stable/datamodules/?h=multitemporalcropclassificationdatamodule#terratorch.datamodules.multi_temporal_crop_classification.MultiTemporalCropClassificationDataModule)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735803b1-a4bf-427f-a1e6-5ac755af33fc",
   "metadata": {
    "id": "735803b1-a4bf-427f-a1e6-5ac755af33fc"
   },
   "outputs": [],
   "source": [
    "datamodule = MultiTemporalCropClassificationDataModule(\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    data_root=f\"{dataset_path}\",\n",
    "    train_transform=[\n",
    "        terratorch.datasets.transforms.FlattenTemporalIntoChannels(),  # Required for temporal data\n",
    "        albumentations.D4(), # Random flips and rotation\n",
    "        albumentations.pytorch.transforms.ToTensorV2(),\n",
    "        terratorch.datasets.transforms.UnflattenTemporalFromChannels(n_timesteps=3),\n",
    "    ],\n",
    "    val_transform=None,  # Using ToTensor() by default\n",
    "    test_transform=None,\n",
    "    expand_temporal_dimension=True,\n",
    "    use_metadata=False, # The crop dataset has metadata for location and time\n",
    "    reduce_zero_label=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup train and val datasets\n",
    "datamodule.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ed3b7-f7dc-486d-ac59-cd781a070925",
   "metadata": {
    "id": "a87ed3b7-f7dc-486d-ac59-cd781a070925"
   },
   "outputs": [],
   "source": [
    "# Mean and standard deviation calculated from the training dataset for all 6 bands, and 3 timesteps, for zero mean normalization.\n",
    "# checking for the dataset means and stds\n",
    "datamodule.means, datamodule.stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08644e71-d82f-426c-b0c1-79026fccb578",
   "metadata": {
    "id": "08644e71-d82f-426c-b0c1-79026fccb578"
   },
   "outputs": [],
   "source": [
    "# checking datasets train split size\n",
    "train_dataset = datamodule.train_dataset\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b86821-3481-4d92-bdba-246568c66c48",
   "metadata": {
    "id": "88b86821-3481-4d92-bdba-246568c66c48"
   },
   "outputs": [],
   "source": [
    "# checking datasets available bands\n",
    "train_dataset.all_band_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264de41-ab16-43cc-9ea2-ee51b0969624",
   "metadata": {
    "id": "9264de41-ab16-43cc-9ea2-ee51b0969624"
   },
   "outputs": [],
   "source": [
    "# checking datasets classes\n",
    "train_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1da2ad-a797-4f4a-ad1a-cd10f9addb01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3a1da2ad-a797-4f4a-ad1a-cd10f9addb01",
    "outputId": "9c948b7c-e02b-4980-a142-b36bcb51a8e4"
   },
   "outputs": [],
   "source": [
    "# plotting a few samples\n",
    "for i in range(5):\n",
    "    train_dataset.plot(train_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7062ddc-a3b7-4378-898c-41abcdf2ee3b",
   "metadata": {
    "id": "b7062ddc-a3b7-4378-898c-41abcdf2ee3b"
   },
   "outputs": [],
   "source": [
    "# checking datasets validation split size\n",
    "val_dataset = datamodule.val_dataset\n",
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1c1c6-9f60-4510-a2da-572c55d03f79",
   "metadata": {
    "id": "ede1c1c6-9f60-4510-a2da-572c55d03f79"
   },
   "outputs": [],
   "source": [
    "# checking datasets testing split size\n",
    "datamodule.setup(\"test\")\n",
    "test_dataset = datamodule.test_dataset\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4072e2f849c0df2d",
   "metadata": {},
   "source": [
    "# Fine-tune Prithvi\n",
    "\n",
    "Here we setup the fine-tuning including which type of task, which head to use and the model parameters. In this case we are doing segemtation task (you can take a look at this and other downstream tasks here [TerraTorch docs](https://ibm.github.io/terratorch/stable/tasks/)) and using a unet decoder. We also set the numbers of images per label with the \"backbone_num_frames\" parameter to allow us to perform multi-temporal classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69d39a-857a-4392-b058-0f4b518edf6e",
   "metadata": {
    "id": "ae69d39a-857a-4392-b058-0f4b518edf6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"../output/multicrop/checkpoints/\",\n",
    "    mode=\"max\",\n",
    "    monitor=\"val/Multiclass_Jaccard_Index\", # Variable to monitor\n",
    "    filename=\"best-{epoch:02d}\",\n",
    ")\n",
    "\n",
    "# Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    devices=1, # Lightning multi-gpu often fails in notebooks\n",
    "    precision='bf16-mixed',  # Speed up training\n",
    "    num_nodes=1,\n",
    "    logger=True, # Uses TensorBoard by default\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=5,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[checkpoint_callback, pl.callbacks.RichProgressBar()],\n",
    "    default_root_dir=\"../output/multicrop\",\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = terratorch.tasks.SemanticSegmentationTask(\n",
    "    model_factory=\"EncoderDecoderFactory\",\n",
    "    model_args={\n",
    "        # Backbone\n",
    "        \"backbone\": prithvi_backbone,\n",
    "        \"backbone_pretrained\": True,\n",
    "        \"backbone_num_frames\": 3,\n",
    "        \"backbone_bands\": [\"BLUE\", \"GREEN\", \"RED\", \"NIR_NARROW\", \"SWIR_1\", \"SWIR_2\"],\n",
    "        \"backbone_coords_encoding\": [], # use [\"time\", \"location\"] for time and location metadata\n",
    "        \n",
    "        # Necks \n",
    "        \"necks\": [\n",
    "            {\n",
    "                \"name\": \"SelectIndices\",\n",
    "                # \"indices\": [2, 5, 8, 11]  # 100m model\n",
    "                \"indices\": [5, 11, 17, 23]  # 300m model\n",
    "                # \"indices\": [7, 15, 23, 31]  # 300m model\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"ReshapeTokensToImage\",\n",
    "                \"effective_time_dim\": 3\n",
    "            },\n",
    "            {\"name\": \"LearnedInterpolateToPyramidal\"},\n",
    "        ],\n",
    "        \n",
    "        # Decoder\n",
    "        \"decoder\": \"UNetDecoder\",\n",
    "        \"decoder_channels\": [512, 256, 128, 64],\n",
    "        \n",
    "        # Head\n",
    "        \"head_dropout\": 0.1,\n",
    "        \"num_classes\": 13,\n",
    "    },\n",
    "\n",
    "    loss=\"ce\",\n",
    "    lr=1e-4,\n",
    "    optimizer=\"AdamW\",\n",
    "    ignore_index=-1,\n",
    "    freeze_backbone=True,  # Speeds up fine-tuning\n",
    "    freeze_decoder=False,\n",
    "    plot_on_val=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fee1e72be7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c27a7aa4f21ea",
   "metadata": {},
   "source": [
    "# Test the fine-tuned model\n",
    "\n",
    "Let's gather and specify the relevant files for carrying out testing. Look for your .ckpt file produced during the fine-tuning process here it is in '../output/multicrop/checkpoints/best-epoch=00.ckpt'. We have also provided a model that has been trained on the full dataset so that we can compare it to our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388aa3db0dc07460",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt_path = \"../output/multicrop/checkpoints/best-epoch=00.ckpt\"\n",
    "\n",
    "# Download best model checkpoint fine-tuned on full dataset\n",
    "best_ckpt_100_epoch_path = \"multicrop_best-epoch=76.ckpt\"\n",
    "\n",
    "if not os.path.isfile(best_ckpt_100_epoch_path):\n",
    "    gdown.download(\"https://drive.google.com/uc?id=1cO5a9PmV70j6mvlTc8zH8MnKsRCGbefm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate test metrics\n",
    "trainer.test(model, datamodule=datamodule, ckpt_path=best_ckpt_100_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62920a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "preds = trainer.predict(model, datamodule=datamodule, ckpt_path=best_ckpt_100_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dfc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data \n",
    "data_loader = trainer.predict_dataloaders\n",
    "batch = next(iter(data_loader))\n",
    "\n",
    "# plot\n",
    "for i in range(batch_size):\n",
    "    sample = {key: batch[key][i] for key in batch}\n",
    "    sample[\"prediction\"] = preds[0][0][0][i].cpu().numpy()\n",
    "\n",
    "    datamodule.predict_dataset.plot(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c88e2d5ab78020",
   "metadata": {},
   "source": [
    "# Fine-tuning via CLI\n",
    "\n",
    "We also run the fine-tuning via a [CLI](https://ibm.github.io/terratorch/stable/quick_start/#training-with-lightning-tasks). All parameteres we have specified in the notebook can be put in a [yaml]( ../configs/prithvi_v2_eo_300_tl_unet_multitemporal_crop.yaml), and can be run using the command below. Take a look at the [TerraTorch docs](https://ibm.github.io/terratorch/stable/tutorials/the_yaml_config/) for how to setup the config.\n",
    "\n",
    "You might want to restart the session to free up GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2553ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's get the config file from github.com.\n",
    "!git init\n",
    "!git remote add origin https://github.com/IBM/ML4EO-workshop-2025.git\n",
    "!git fetch --all\n",
    "!git checkout origin/main -- \"Prithvi-EO/configs/prithvi_v2_eo_300_tl_unet_multitemporal_crop.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf05ebc81b9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fine-tuning\n",
    "!terratorch fit -c \"Prithvi-EO/configs/prithvi_v2_eo_300_tl_unet_multitemporal_crop.yaml\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
